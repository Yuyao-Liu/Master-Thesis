# Mobile Robot Manipulator Control for Interacting with 1-DoF Mechanisms

## Overview

This project enables a differential-drive mobile manipulator (a MiR base with a UR5e arm, known as the **Heron** robot) to autonomously interact with unknown one-degree-of-freedom (1‑DoF) mechanisms such as doors, drawers, and windows. The core objective is to combine adaptive control, navigation, and online estimation so that the robot can open or slide mechanisms without prior knowledge of their exact kinematics. Building on prior adaptive controllers for fixed manipulators, we introduce a **holistic control framework** coordinating the mobile base and arm motion. This allows the robot to reposition itself during interaction for larger opening angles and to avoid collisions. The system was validated in both simulation and real-world experiments, demonstrating robust door-opening and drawer-pulling behaviors.

**Key Features:**

-   *Nonlinear Base Navigation:* A custom feedback controller drives the wheeled base to a suitable pre-interaction pose with high precision in position and orientation, even under the base’s non-holonomic (differential-drive) constraints.
    
-   *Whole-Body Motion:* An **extended Jacobian** formulation integrates the base and arm kinematics, enabling simultaneous movement of the mobile base and manipulator for coordinated pushing/pulling of the mechanism.
    
-   *Null-Space Optimization:* Secondary objectives – maintaining a safe distance between the base and arm, and aligning the base’s heading with the end-effector’s motion direction – are achieved via null-space control techniques. This ensures safety (no base-arm collisions) and compensates for the base’s inability to move sideways.
    
-   *Online Adaptive Estimation:* An onboard estimator learns the mechanism’s properties (e.g. hinge axis orientation or linear track) in real time. Using the robot’s motion feedback, it converges on the mechanism’s rotation center or sliding direction on-the-fly, so the robot doesn’t require these parameters in advance.
    

Overall, the framework allows a mobile manipulator to approach an unknown door or drawer, open it through a coordinated base-and-arm motion, and simultaneously figure out the mechanism’s constraints. This unified system addresses key challenges in mobile manipulation for 1-DoF devices.


## Usage

The project provides example scripts and modules to run both **simulated experiments** and **real-world robot runs**. The typical usage involves the following sequence: (1) navigate the mobile base to an approach position, (2) execute a whole-body motion (base + arm) to open or slide the mechanism, and (3) estimate mechanism parameters online during the motion. Below are instructions for running the system:

-   **Simulation:** You can run the entire pipeline in a physics-free simulation (kinematic simulation with visualization). Ensure you installed the `smc` package and have a display (MeshCat) for visualization. To simulate a scenario, execute the main control script (for example, `src/mainloop.py`) with Python:
    
    ```bash
    python src/mainloop.py
    ```
    
    By default, this will run in simulation mode (`args.real=False` in the script) and bring up a MeshCat web viewer showing the robot and the mechanism. The script is configured to perform a complete cycle: first the base drives to a predefined **pre-interaction pose**, then the arm moves to grasp the handle, and finally the **whole-body controller** moves both the base and arm to execute the opening motion. You can modify the `task` variable in the script (or via command-line arguments if exposed) to choose different mechanism types (e.g., `task = 1` for a door, `2` for an outward-swinging door, `3` for a sliding door, `4` for a drawer, etc., corresponding to the four types described below). The input to the navigation module is a target pose for the base (specified in the script as `parking_lot` coordinates). The input to the whole-body controller is a desired end-effector trajectory, defined implicitly by a handle pose and a constant end-effector velocity in the tool frame (e.g. the robot “pushes” or “pulls” at a fixed speed). During execution, the program will print status messages and at the end it may save log files (e.g., `q_park.mat` for the base trajectory during navigation, or estimator logs) for analysis. The expected output in simulation is the robot moving in the visualizer: you should see the base drive into position, the arm reach out, and then the door or drawer being “opened” by the coordinated motion. No physical forces are modeled in this simulation; the framework treats the mechanism as a constraint path for the end-effector.
    
-   **Real Robot:** To run on the actual Heron robot, make sure the hardware is powered and networked. In the code or via command-line, set `--real True` (or edit `args.real = True` in the script) and provide the UR5e’s IP address (e.g., `--robot_ip 192.168.1.102`) if required. Ensure that the **base’s localization** is available (the code might use initial pose from a localization topic) and that you have a way to send velocity commands to the base (e.g., ROS2 navigation stack or a custom interface). Running the main script in real mode will command the physical robot: the mobile base will drive to the specified approach pose, the arm will move to contact the mechanism, and then the base and arm will move together to perform the opening. The **online estimator** will be running in the background, using force/torque sensor feedback (if available on the arm’s wrist) and the motion to update its estimate of the door’s hinge or slider parameters. Expected output on the real robot is the successful opening of the door/drawer. The script will attempt to open the gripper, etc., at the end of the motion (ensure your gripper is connected if you intend to actually latch onto a handle). All movements are computed at a control frequency of 500 Hz in simulation (and about 50 Hz on real hardware due to network and safety limits).
    

**Module Overview:** The system consists of three main components which the scripts launch in sequence:

1.  **Navigation Controller:** a nonlinear pose controller for the differential-drive base. You provide a target (x, y, θ) for the base (e.g., in front of a door), and this module drives the base to that pose. It uses a feedback law that controls the base’s linear and angular velocities to reduce the distance and heading error to zero. In practice, the base will follow a smooth S-shaped path to correct its orientation and position simultaneously. Once the base is within a small error threshold of the goal (e.g., within 1–2 cm and a few degrees), the navigation step completes. In simulation, the script will automatically log the trajectory and errors; on a real robot, you would observe the base stopping at the desired spot relative to the mechanism.
    
2.  **Whole-Body Controller:** once in position, the controller switches to **extended Jacobian mode** for simultaneous base and arm motion. The input is a desired end-effector motion – for example, “rotate the door about its hinge” or “pull the drawer straight out”. In the provided examples, this is realized by commanding a constant velocity to the end-effector in its local frame (e.g., the tool moves in a circle or straight line relative to itself). The controller uses an **extended Jacobian** that treats the mobile base’s coordinates and the arm’s joints together as a single kinematic chain. At each control cycle, it computes the necessary wheel speeds and arm joint velocities that cause the end-effector to follow the commanded motion. This happens while respecting joint limits and kinematic constraints. You do not need to manually tune the base vs arm contribution – the extended Jacobian automatically distributes motion. The expected outcome is that the end-effector maintains the desired trajectory (e.g., moving along the door’s arc or the drawer’s line) while the base repositions to assist the arm.
    
3.  **Online Estimator:** throughout the whole-body motion, the system runs an estimator that learns the mechanism’s properties in real time. Initially, the robot does not know if the door opens by rotation or translation, nor the location of the hinge or the distance of travel. The estimator monitors the end-effector’s force and velocity to deduce the **motion axis and curvature** of the mechanism. Essentially, it tracks the direction in which the end-effector is actually moving and how that motion curves. The output is an estimate of the hinge orientation (for a door) and the radius of the door’s swing, or an identification that the motion is linear (infinite radius for a sliding mechanism). The estimator uses an adaptive law that updates these parameters continuously; for example, as the door starts to move, the estimator will lock onto the plane of motion (within a fraction of a second). In practice, the script logs the estimated values over time (and you might see them printed or saved in a `.mat` file). This information could be used to adjust the controller on the fly; in our implementation, it primarily confirms that the robot has correctly inferred the mechanism type by the end of the motion. For instance, the heading alignment of the base is also corrected using this estimate, ensuring the base eventually points along the motion direction.
    
## Dataset and Experimental Setup

The experimental setup consists of the **Heron mobile manipulator** and a set of four representative 1-DoF mechanisms in a lab environment. The Heron robot integrates a 6-DOF Universal Robots UR5e arm mounted on a differential-drive MiR100 base, along with a Robotiq two-finger gripper for interacting with handles. In simulation, we use a kinematic model of this robot (the UR5e’s URDF combined with a planar joint model for the base) within the Pinocchio library. The environment in simulation is kept simple – the mechanisms are not physically modeled; instead, the desired end-effector trajectories for opening each mechanism are predefined. In real-world tests, the robot was placed in front of actual doors and drawers, and we measured its performance in those scenarios.

**Mechanism Types:** We evaluated four types of 1-DoF mechanisms, which cover common doors and drawers:

-   **Type I: Rotational door with a vertical hinge axis** – e.g., a typical swing door attached at the side. The door’s motion is a rotation in the vertical plane. In experiments, the door had an approximate rotation radius of 0.8 m (distance from hinge to handle). The robot had to push the door open by moving the handle in an arc.
    
-   **Type II: Rotational door with a horizontal hinge axis** – e.g., an oven door or a fold-down hatch, hinged at the bottom or top. This motion is also rotational but in a horizontal plane (the door swings down or up). We tested with effective radii of about 0.4 m and 0.5 m (shorter radius since the hinge is at the bottom and the handle is closer). The robot had to **pull** the door open (as it swings downward).
    
-   **Type III: Sliding door** – a door that translates laterally on a track (prismatic joint). Here the end-effector motion is a straight line horizontally. The robot needs to grasp and slide the door to the side.
    
-   **Type IV: Pull-out drawer** – another prismatic joint mechanism where the motion is a straight line outward. The robot grasps the drawer handle and pulls it towards itself.
    

For each type, we define a **pre-interaction pose** for the robot base (e.g., in front of the door at a certain offset and angle) and a **handle grasp pose** for the end-effector. These were chosen so that the arm can reach the handle and have some range of motion to execute the opening. For instance, for the swing door (Type I), the robot is positioned to the side of the door with its base at a 30° angle relative to the doorway. This positioning helps the base stay out of the way of the door’s path and gives the arm clearance to push. For the sliding door and drawer, the robot is generally facing the mechanism directly (0° offset) since alignment is simpler for linear motion.

During the experiments, the end-effector is commanded to move with a constant velocity profile: for rotational joints, a constant angular velocity (e.g. ~4.5°/s) around the hinge, and for prismatic joints, a constant linear speed. This results in a smooth opening motion – a circular trajectory for Types I & II, and a straight-line trajectory for Types III & IV. We do not rely on external motion capture or detailed environment maps; the approach is adaptive. The robot’s onboard estimation quickly determines the necessary motion plane: for a revolute mechanism, it will sense the curvature and adjust accordingly, and for a prismatic mechanism, it will recognize the lack of curvature (straight line).

**Data Collected:** We record the robot’s joint states, end-effector trajectory, base pose, and forces/torques during each trial. Key metrics include:

-   **Trajectory tracking error:** difference between the end-effector’s actual path vs. the desired path (arc or line).
    
-   **Base-arm distance:** the projected distance between the base and end-effector, which should stay above a safety threshold.
    
-   **Base heading vs. end-effector direction:** the alignment angle between where the base is facing and the direction of end-effector motion (ideally this goes to 0 when aligned).
    
-   **Estimated vs. true mechanism parameters:** for simulation we know the “true” hinge or slider parameters, so we compare the estimator’s learned radius/axis to the ground truth.
    

These data help evaluate the performance as discussed in the Results section. The provided repository may include some logged examples or MATLAB `.mat` files saved from runs (e.g., `q_park.mat` containing base trajectory for navigation tuning, or `es_*.mat` for estimator history). You can use these to plot error curves or to further analyze the behavior of the system.

## Methodology

This section provides a brief overview of the control and estimation methods used in the project:

-   **Nonlinear Navigation Controller:** The mobile base is controlled by a pose stabilizing algorithm for differential drive robots. We employ a nonlinear feedback controller (based on unicycle kinematics) that takes the robot’s current pose and a target pose and outputs linear and angular velocity commands. The controller uses polar coordinates (distance $\\rho$, heading angle $\\gamma$, and orientation error) to guide the base. For example, the linear velocity might be set proportional to $\\rho\\cos\\gamma$ and the angular velocity to a term that turns the robot toward the goal while damping out overshoot. Specific gains (in our tests $k\_1 = k\_3 = 1.0$, $k\_2 = 2.0$) ensure the base converges smoothly without oscillation. As a result, the robot can drive to the door or drawer handle position reliably, aligning itself appropriately before manipulation. This controller was validated in both simulation and on the real robot, showing precise positioning (errors of only a few centimeters and degrees) even with the base’s non-holonomic constraint.
    
-   **Extended Jacobian Whole-Body Controller:** Once the base is in position, the robot needs to coordinate the motion of its arm and base to actually open the mechanism. We extended the classic resolved-rate motion control (Jacobians for manipulator) to include the base’s motion degrees of freedom. Essentially, we augment the UR5e’s 6-DoF Jacobian with additional rows/columns representing the base’s planar movement (x, y translation and heading rotation). This **extended Jacobian** maps the combined joint velocities of the base+arm to the end-effector’s spatial velocity. We then use an inverse kinematics approach (CLIΚ – Closed-Loop Inverse Kinematics) to solve for the joint velocity command that achieves the desired end-effector velocity. We use a damped pseudoinverse solution by default, which adds a small Tikhonov regularization to handle singularities. By commanding the end-effector in its local frame (e.g., move *forward* in the tool frame at a certain speed), the controller naturally produces a circular motion for revolute joints or a straight line for prismatic joints. The extended Jacobian ensures that both the wheels and the arm joints move in a coordinated fashion: for example, when opening a door, the base will drive forward and sideways while the arm rotates, so that the end-effector follows the door’s arc without leaving the handle. This full-body coordination greatly expands the reachable workspace – the robot can open the door to a wide angle that the arm alone could not achieve without moving the base.
    
-   **Null-Space Optimization for Secondary Tasks:** In addition to the primary task (moving the end-effector along the desired trajectory), we introduce secondary objectives to improve safety and performance. These secondary goals are enforced using null-space projection methods: the idea is to command additional joint velocities that do not affect the end-effector’s motion (lying in the null space of the Jacobian). Two main optimizations are employed:
    
    -   *Distance Regulation:* We keep the distance between the base and the end-effector above a minimum threshold (e.g., 0.75 m). If the arm gets too close to the base (which could risk a collision with the robot’s body), the controller adjusts the base’s velocity to increase the separation. This is done without disturbing the end-effector’s trajectory if possible. Essentially, we add a null-space control vector that drives the base backwards or forwards to maintain distance.
        
    -   *Heading Alignment:* We align the base’s orientation with the direction of end-effector travel. For a differential-drive base, it’s important to minimize sideways motion, so the base should “face” the direction the end-effector is moving. We implement a controller $z\_2$ that adds an angular velocity command to the base (in the null space) to minimize the angle between the base’s forward axis and the instantaneous end-effector velocity vector. This reduces lateral slippage and helps keep the end-effector movement feasible. We include a proportional-integral (PI) term in this heading alignment controller – the integral term eliminates steady-state errors in alignment. Without the integral action, we observed a small residual angle (~8°) between the base and arm motion that persisted, causing the arm to eventually reach its limits. With the PI correction, the base and end-effector velocities become fully aligned, yielding a cleaner motion.
        
    -   *Adaptive Damping:* Additionally, to avoid arm kinematic singularities (like when the arm is fully stretched out), we employ an adaptive damping factor in the inverse kinematics solution. This effectively slows down the arm’s motion as it nears singular configurations by damping the pseudoinverse, preventing erratic movements or instability. The manipulability measure of the Jacobian is monitored, and the damping is adjusted to keep the system away from singular configurations.
        
    
    These optimizations are applied in a way that **primary task (end-effector trajectory)** is always prioritized. If there is a conflict (for example, the base cannot both align and maintain distance perfectly while also keeping the end-effector on track), the controller will sacrifice the secondary objectives to ensure the end-effector follows the desired path. This was a conscious design choice to guarantee the robot completes the opening task safely. The results confirmed that even when secondary goals couldn’t be met exactly (such as the base-arm distance oscillating slightly), the end-effector still maintained its trajectory and no collisions occurred.
    
-   **Online Constraint Estimator:** A major challenge is handling unknown mechanism parameters. We implemented an **adaptive estimator** that runs in parallel with the controller to identify the mechanism’s constraint (revolute or prismatic, and the axis of motion). The estimator uses the robot’s sensed wrench (force/torque at the end-effector) and the discrepancy between the end-effector’s intended motion and actual motion to update two things: the unit vector $\\hat{x}\_h$ pointing along the mechanism’s motion direction (e.g., the hinge axis direction for a door, or the sliding direction for a drawer), and the curvature $\\kappa$ of the path (which is $1/r$ for a door of radius $r$, or $0$ for a linear slide). The algorithm is inspired by adaptive control theory – it uses projection and update laws to ensure the estimates converge. In simple terms, as the robot starts moving the door, the estimator observes the **error between the expected motion and the constrained motion**. It then rotates the estimated axis $\\hat{x}\_h$ to reduce that error and adjusts $\\kappa$ to account for any curvature in the path. Notably, if the door is stuck or hasn’t moved yet, the estimator will initially be off (since it might assume a direction), but as soon as the mechanism allows motion, the estimator quickly locks on to the correct direction. Our results show the heading alignment error (angle between estimated direction and actual velocity) decays rapidly to zero in all tested cases. Similarly, the curvature estimate $\\hat{\\kappa}$ converges to the true value, correctly distinguishing between rotating and sliding mechanisms. Within about 0.25 seconds of movement, the estimator becomes stable and thereafter provides an accurate parameter that could be used by the controller to, for example, better distribute motion between base and arm. In our implementation, we primarily used the estimator’s output to inform the heading alignment controller (so that the base knows which way to point) and to validate that the mechanism type was identified. The estimator makes the system robust: even with large initial misalignment or uncertainty, the robot can learn the mechanism’s behavior on the fly and adjust accordingly, rather than needing a perfect model upfront.
    

In summary, the methodology combines **control** (navigation and whole-body motion) with **learning** (online estimation) to handle unknown tasks. The navigation brings the robot into the right neighborhood, the whole-body controller with extended Jacobian handles the simultaneous motion while keeping the system safe, and the estimator adapts to the mechanism’s unknown parameters. This framework is general for 1-DoF mechanisms – whether the joint is rotary or linear, the robot will figure it out and execute the appropriate opening motion.
